---
title: "Biometry module 6"
output: html_document
---

#Introduction
Travail en groupe par rapport à l'étude de la biométrie d'une population de Belgique. Les données ont été récolté par chaque membre de la classe. Il y a différentes variable qui ont été mis dans notre tableau de données. 
Ces différentes variables nous permettront d'établir si les différents individus sont obèses. On a mesures d'autres variables qui elles pourraient être les causes d'une obesité ou non.
# But
Notre but est déterminer le taux d'obesité dans notre échantillonnage. Ainsi qu'essayer d'en déduire les causes d'obesité.

# Matériel et méthodes utilisées
Nous avons utilisé Markdown et les données que tous les membres de la classe ont prélevé pour établir un tableau de données par la suite.

# Résultats
##Importation des données et des outils nécessaires
```{r}
SciViews::R
(biometry <- read_csv("https://docs.google.com/spreadsheets/d/1UfpZvx1_nd7d10vIMAfGVZ1vWyIuzeiKxPL0jfkNSQM/export?format=csv", locale = locale(decimal_mark = ",")))

```

## Filtrage des données
Il y a beaucoup de NA et d'espace inutile dans notre tableau.

```{r}
#biometry <- filter (biometry, taille != NA)

# encore à modifier
```

## Etudes des données
### Tableau résumé
```{r}
rmarkdown::paged_table(biometry)
biometry1 <- filter (biometry, taille>0, masse >0 , )
biometry_summarise <- summarise(biometry1 ,
  "moyenne taille" = mean(taille), 
  "moyenne masse" = mean(masse))
knitr::kable(biometry_summarise, digits = 2)





```

#Test chi carré

##on peut se demander si la valeur de notre IC diffère en fonction de notre appartenance ou non au hainaut.

```{r}
biometry_IMC <- mutate(biometry, IMC = masse/taille^2)
biometry2 <- mutate(biometry_IMC, surpoid = IMC >= 25 & IMC < 30, obese = IMC> 30, normal = IMC <25 & IMC >= 18.5 , souspoid = IMC < 18.5)

biometry2$IMC <-as.factor(biometry2$IMC)

skimr::skim(biometry2)
```

#####Graphiques / visualisation:


```{r}
chart(biometry2,~ IMC %FILL=% hainaut) + geom_bar()
```


#Test de student

##Est ce que la masse corrigée des personnes est identique dans la population selon le genre ou es ce que l'un des genres est en moyenne plus lourd que l autre ?:

observons ceci tout d'abord par une représentation graphique pour avoir une idée.


#####Graphique
```{r}
biometry<-filter(biometry, genre !="NA")

give_n <- function(x)
  c(y = max(x) * 1.1, label = length(x)) 

chart(data = biometry, masse_corr ~ genre %fill=% genre) +
  geom_boxplot(na.rm = TRUE) + stat_summary(fun.data = give_n, geom = "text", hjust = 0.5)
```

Sur le graphique, il semble que les hommes (sex == "h") tendent à avoir une masse corrigée plus grande (variable masse-corr) que les femmes (sex == "f"), mais cette différence est-elle significative ou peut-elle être juste liée au hasard de l’échantillonnage ? Pour y répondre, nous devons élaborer un test de student qui va confronter les hypothèses suivantes (en se basant sur les moyennes) :

#####test de student

voici nos 2 hypothèses :

H0:la différence des moyennes entre mesures pour les femmes et pour les hommes= 0

H1:la différence des moyennes entre mesures pour les femmes et pour les hommes≠ 0





test de student :

```{r}
t.test(data = biometry, masse_corr ~ genre,
  alternative = "two.sided", conf.level = 0.95, var.equal = TRUE)
```
######Analyses 

Prenons une valeur de α de 5% , (α = 0.05).On compare notre valeur de α avec notre valeur de p qui est de: p-value=5.601e-09.

comme p <<<< α on rejette Ho qui se situe dans la zone de rejet.

representation graphique des distributions:


```{r}
biometry<-filter(biometry, genre !="NA",masse_corr !="NA")

biometry %>.%
group_by(.,genre) %>.%
summarise(.,"moyenne" = mean(masse_corr),
"ecart_type" = sd(masse_corr))



```
pour les femmes :

```{r}
.mu <- 65.2120; .s <- 15.18; .mu + .s * qt(0.05
, df = 248, lower.tail = FALSE)

.mu <- 65.2120; .s <- 15.18; .mu + .s * qt(5.601e-09
, df = 248, lower.tail = FALSE)

```


```{r}
# Student's t distribution (density probability) with parameters:
.mu <- 65.2120; .s <- 15.18; .df <- 248 # .mu, .s (sigma) and .df
.col <- 1; .add <- FALSE # Plot parameters
.x <- seq(-4.5*.s+.mu, 4.5*.s+.mu, l = 1000)     # Quantiles
.d <- function (x) dt((x-.mu)/.s, df = .df)/.s   # Distribution function
.q <- function (p) qt(p, df = .df) * .s + .mu    # Quantile for lower-tail prob
.label <- bquote(t(.(.mu), .(.s), .(.df)))       # Parameters
curve(.d(x), xlim = range(.x), xaxs = "i", n = 1000, col = .col,
  add = .add, xlab = "Quantiles", ylab = "Probability density") # Curve
abline(h = 0, col = "gray") # Baseline
abline(v = 90, col = "red")
```

le quantile correspondant à l'hypothèse H0 est situé dans la zone de rejet ( a gauche du quantile α(verticale rouge)) on rejette donc l'hypothèse H0.




pour les hommes :

```{r}
.mu <- 78.3392; .s <- 18.97183; .mu + .s * qt(0.05
, df = 248, lower.tail = FALSE)

.mu <- 78.3392; .s <- 18.97183; .mu + .s * qt(5.601e-09
, df = 248, lower.tail = FALSE)

```

```{r}
# Student's t distribution (density probability) with parameters:
.mu <- 78.3392; .s <- 18.97183; .df <- 248 # .mu, .s (sigma) and .df
.col <- 1; .add <- FALSE # Plot parameters
.x <- seq(-4.5*.s+.mu, 4.5*.s+.mu, l = 1000)     # Quantiles
.d <- function (x) dt((x-.mu)/.s, df = .df)/.s   # Distribution function
.q <- function (p) qt(p, df = .df) * .s + .mu    # Quantile for lower-tail prob
.label <- bquote(t(.(.mu), .(.s), .(.df)))       # Parameters
curve(.d(x), xlim = range(.x), xaxs = "i", n = 1000, col = .col,
  add = .add, xlab = "Quantiles", ylab = "Probability density") # Curve
abline(h = 0, col = "gray") # Baseline
abline(v=109.66, col = "red")
```

le quantile correspondant à l'hypothèse H0 est situé dans la zone de rejet ( a gauche du quantile α(ligne rouge)) on rejette donc l'hypothèse H0.

######Discussion

On en conclu donc que l hypothèse H1 est correcte et que la moyenne de la masse corrigée dans notre population sera significativement plus importante chez les hommes que chez les femmes.

#Test de Wilcoxon

##On peut maintenant se demander si la taille des personnes est identique dans la population selon le genre ou es ce que l'un des genres est en moyenne plus grand que l autre ?:


Dans le test de student nous avons supposé que la distribution de départ était de type normal.Or lorsqu'on a un faible échantillonage on peut douter que la distribution suis bien une loi normale on va donc utiliser un autre test celui de Test de Wilcoxon-Mahn-Withney une version non-paramétrique du test de student.

#####Graphique

```{r}
biometry<-filter(biometry, genre !="NA")

give_n <- function(x)
  c(y = max(x) * 1.1, label = length(x)) 

chart(data = biometry, taille ~ genre %fill=% genre) +
  geom_boxplot(na.rm = TRUE) + stat_summary(fun.data = give_n, geom = "text", hjust = 0.5)
```

#####Analyses

Sur le graphique, il semble que les hommes (sex == "h") tendent à avoir une taille plus grande (variable taille) que les femmes (sex == "f"), mais cette différence est-elle significative ou peut-elle être juste liée au hasard de l’échantillonnage ? Pour y répondre, nous devons élaborer un Test de Wilcoxon-Mahn-Withney qui va confronter les hypothèses suivantes (en se basant sur les moyennes) :



voici nos 2 hypothèses 

H0:P(taillef>tailleh)=P(taillef<tailleh)
H1:P(taillef>tailleh)≠P(taillef<tailleh)

######Test de Wilcoxon-Mahn-Withney:


```{r}
wilcox.test(data = biometry, taille ~ genre,
  alternative = "greater", conf.level = 0.95)
```

######Analyses 

Prenons une valeur de α de 5% , (α = 0.05).On compare notre valeur de α avec notre valeur de p qui est de: p-value=.

comme p <<<< α on rejette Ho qui se situe dans la zone de rejet.

representation graphique des distributions:


```{r}
biometry<-filter(biometry, genre !="NA",taille !="NA")

biometry %>.%
group_by(.,genre) %>.%
summarise(.,"moyenne" = mean(taille),
"ecart_type" = sd(taille))



```

#####Discussion

On en conclu donc que l hypothèse H1 est correcte et que la moyenne de la taille dans notre population sera significativement plus importante chez les hommes que chez les femmes.

representation graphique des distributions:


```{r}
biometry<-filter(biometry, genre !="NA",taille !="NA")

biometry %>.%
group_by(.,genre) %>.%
summarise(.,"moyenne" = mean(taille),
"ecart_type" = sd(taille))



```

#Analyses des variances et modèle de l'ANOVA/test de Kruskal-Wallis :

##imaginons que nous voulons comparer la masse corrigée des individus en fonction de leur age (on formera une variable facteur en formant des groupes d'ages(plus de deux)), on ne peut plus utiliser le test de student ou de wilcoxon car un compare plus de deux population ! On va donc utiliser le test de Kruskal-Wallis ou le modèle de l'ANOVA:

```{r}
## Cutting biometry$age into biometry$age_rec
biometry$age_rec <- cut(biometry$age, include.lowest=FALSE,  right=TRUE,
                        breaks=c(0, 20, 50,100))

biometry$age_rec <- as.ordered(biometry$age_rec)

skimr::skim(biometry)

```

#####Analyses

Nous pourions comparer chaque groupe l'un avec l'autre c'est long et nous ne le ferons pas car à chaque test nous prenons un risque de nous tromper. Le risque de se tromper au moins une fois dans l’ensemble des tests est alors décuplé en cas de tests multiples.

#####Graphiques et visualisations

```{r}
biometry %>.%
  group_by(., age_rec) %>.%
  filter(.,age_rec !="NA",masse_corr !="NA")%>.%
  summarise(., mean = mean(masse_corr), sd = sd(masse_corr), count = sum(!is.na(masse_corr)))
```

```{r}
biometry %>.%
  group_by(., age_rec) %>.%
  filter(.,age_rec !="NA")%>.%

chart(data = .,masse_corr ~ age_rec) + # Je réalise un graphique 
  geom_violin() + # Je réalise un graphique en violon
  geom_jitter(width = 0.05, alpha = 0.5) + # J'ajoute les points sur le graphique 
  stat_summary(geom = "point", fun.y = "mean", color = "green", size = 9) # J'ajoute la moyenne en vert
```

#####Analyses

On semble voir une différence entre les différentes classes mais cette différence est t'elle significatice ou npas ? pour le savoir on va réaliser  un test de Kruskal-Wallis ou utiliser le modèle de l'ANOVA:

#####ANOVA ou Kruskal-Wallis ?

test anova:

on a maintenant prit connaissance de nos données on va se demander si il y a homoscédasticité des variances via un test de Barlett:

dont les hypothèses sont:

H0:var1=var2=...=vark     (homoscédasticité)
H1:∃(i,j) tel que vari≠varj       (hétéroscédasticité)

```{r}

biometry %>.%
  group_by(., age_rec) %>.%
  filter(.,age_rec !="NA",masse_corr!="NA")%>.%
bartlett.test(data = .,masse_corr ~ age_rec)
```

ici la p-value est plus petite qu'alpha (0.05) ont rejette donc H0, on a besoin que H0 soit non rejettée pour utiliser le modèle de l'ANOVA sinon on se rabattra sur un test de Kruskal-Wallis:

```{r}

biometry %>.%
  group_by(., age_rec) %>.%
  filter(.,age_rec !="NA",masse_corr!="NA")%>.%
bartlett.test(data = .,log(masse_corr) ~ age_rec)
```

ici la p-value est suppérieur a alpha(0.05) on peut donc utiliser l'ANOVA avec log(masse-corr)

######visualisation:

```{r}
biometry %>.%
  group_by(., age_rec) %>.%
  filter(.,age_rec !="NA",masse_corr !="NA")%>.%
  summarise(., mean = mean(log(masse_corr)), sd = sd(log(masse_corr)), count = sum(!is.na(log(masse_corr))))
```

```{r}
biometry %>.%
  group_by(., age_rec) %>.%
  filter(.,age_rec !="NA")%>.%

chart(data = .,log(masse_corr) ~ age_rec) + # Je réalise un graphique 
  geom_violin() + # Je réalise un graphique en violon
  geom_jitter(width = 0.05, alpha = 0.5) + # J'ajoute les points sur le graphique 
  stat_summary(geom = "point", fun.y = "mean", color = "green", size = 9) # J'ajoute la moyenne en vert
```

avant de continuer on dois vérifier si la distibution est bien de type normale pour pouvoir utiliser l'ANOVA :

```{r}
biometry %>.%
  group_by(., age_rec) %>.%
  filter(.,age_rec !="NA")%>.%

car::qqPlot(.[["masse_corr"]], distribution = "norm",
  envelope = 0.95, col = "green", ylab = "masse_corr")

```

on observe que la distribution sort des marges pour les valeurs plus importante on prèferera donc utiliser le modèle non paramétrique du test de Kruskal-Wallis

#####Test de Kruskal-Wallis

Dans le test de Kruskal-Wallis, sous H0 nous avons le même rang moyen (noté mr) pour chaque groupe parmi k. Sous H1, au moins deux groupes ont des rangs moyens différents:

H0:mr1=mr2=...=mrk

H1:∃(i,j) tel que mri≠mrj

```{r}
kruskal.test(data = biometry, masse_corr ~ age_rec)
```

#####Analyses

comme p-value est bien plus petit qu'aplha (0.05) on rejette H0 et on peut dire qu'il existe au moins une différence significative entre les ratios .

#####Test post hoc

on a déterminer une différencee significative mais est t'elle présente entre tout les groupes ou seulement entre certain ? on réalise un test post hoc pour le savoir(test de tukey):

```{r}
summary(kw_comp. <- nparcomp::nparcomp(data = biometry, masse_corr ~ age_rec))
```

```{r}
plot(kw_comp.)
```

#####Discussion

Ici, toutes les différences sont considérées comme significatives sauf  la comparaison des [20-50]-[50-100] avec une valeur P tout juste non significative de 6.833583e-02 mais à prendre avec des pincettes étant donné sa proximité du seuil.



# Discussion

# Conclusion




